---
title: "Project 2: Misinformation"
date: "April 2021"
output: 
  html_document:
    highlight: haddock
    theme: journal
    number_sections: no
    toc: yes
    toc_depth: 5
    toc_float: yes
---

<style>
div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 20px;}
</style>

<style>
div.medblue { background-color: #b3d1ff; border-radius: 5px; padding: 5px;}
</style>

<style>
div.darkblue { background-color: #9ac2ff; border-radius: 5px; padding: 5px;}
</style>



```{r setup, include = FALSE}
set.seed(95126)
knitr::opts_chunk$set(
  eval = TRUE,
  echo = TRUE,
  warning = FALSE,
  message = FALSE
)
```


## Power Calculations

We use the 2x2 template with our own parameters. Importantly, we use b0 = b1 = 0.5 in order to have enough power to detect an effect size of at least 0.5 due to each intervention. We also choose sigma to 2.5 based on the fact that our outcome is scored from 1 to 7. We also want the interaction term to be 0.

### Load required packages

```{r load_packages}
# Ensure that pacman is installed for package management and loading.
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse)
pacman::p_load(randomizr)
pacman::p_load(estimatr)
pacman::p_load(kableExtra)
pacman::p_load(ggthemes)
pacman::p_load(reshape2)
pacman::p_load(bindata)
```


```{r lm_model}
# analysis of a simulated experiment
lm_interacted_model <- function(N,
                                # probability of treatment assignment, 
                                # separate entry for each factor, 
                                # entries will be normalized to sum to 1
                                p_list = list(c(0.75, 0.25),
                                              c(0.25, 0.5, 0.25),
                                              c(0.25, 0.75)), 
                                # intercept (potential outcome at all baseline)
                                b0 = 0, 
                                # main effects above baseline, 
                                # separate entry for each factor level
                                b_main_list = list('w1.1' = c(0.1),
                                                   'w2.1' = c(0.2),
                                                   'w2.2' = c(0.3),
                                                   'w3.1' = c(0.5)), 
                                # 2-way interactions
                                b_2wy_list = list('w1.1:w2.1' = c(0.01),
                                                  'w1.1:w2.2' = c(0.02),
                                                  'w1.1:w3.1' = c(0.03),
                                                  'w2.1:w3.1' = c(0.04),
                                                  'w2.2:w3.1' = c(0.05)), 
                                # 3-way interactions
                                b_3wy_list = list('w1.1:w2.1:w3.1' = c(0.001),
                                                  'w1.1:w2.2:w3.1' = c(0.002)),
                                # noise, residual error
                                sigma = 1 
) {
  
  K <- length(p_list) # number of factors
  degree = ifelse(!is.null(b_3wy_list), 3, 2) # max order of interaction in the model
  
  # Count number of levels in each factor
  L_list <- list()
  for(k in 1:length(p_list)){
    L_list[[paste0('L', k)]] <- length(p_list[[k]]) # naming the levels
  }
  number_marginal = (sum(unlist(L_list))-length(L_list)) # number of marginal effects
  
  # complete randomization of treatment assignment
  wmat <- as.data.frame(lapply(1:K, function(k)
    factor(
      complete_ra(N, 
                  num_arms = L_list[[k]], 
                  prob_each = p_list[[k]]),
      levels = paste0('T', 1:L_list[[k]]),
      labels = 1:L_list[[k]]
    ) ))

  # add names for the treatment assignment  
  colnames(wmat) <- paste0('w', 1:K, '.')
  
  # simulation based on provided data generation process 
  mmat <- model.matrix(formula(paste0('~.^', degree)) , as.data.frame(wmat)) # indicators for whether to include w1, w2 and the interaction
  betas <- unlist(c(b0, b_main_list, b_2wy_list, b_3wy_list)) # define the betas
  y <- as.vector(mmat %*% betas + rnorm(N, sd = sigma)) # simulate outcomes
  
  # analysis of outcomes by including interaction in the model
  lm_long <- lm_robust(y~., data = as.data.frame(cbind(y, mmat[,-1]))) # regression of simulated outcome on all the indicators except intercept

  # analysis of outcomes by excluding interactions in the model  
  lm_short <- lm_robust(y~., data = as.data.frame(cbind(y, mmat[,1:number_marginal+1]))) # regression of simulated outcome on all the indicators except intercept and interaction
  
  return(list(lm_long,lm_short))
}
```

```{r power_simulated}
possible.ns <- seq(from = 100, to = 2000, by = 50 ) # possible total sample size
power.interaction <- rep(NA, length(possible.ns)) # save power to detect the specified interaction effect
power.onemarginal <- rep(NA, length(possible.ns)) # save power to detect at least one of the marginal effects
power.allmarginals <- rep(NA, length(possible.ns)) # save power to detect all marginal effects, with Bonferroni correction
power.all_FDR <- rep(NA, length(possible.ns)) # save power to detect all marginal effects, with FDR control
```

```{r}
# setup for hypothesis testing
alpha <- 0.05  # significance level
sims <- 5e2 # 500 simulations
hypotheses <- c('two.tailed', 'two.tailed', 'two.tailed') # hypothesis type for marginal effect 1, marginal effect 2, and interaction effect
n <- length(hypotheses) # total number of hypotheses 
m <- 3 # index of particular interaction to test

# design choice
p_list <- list(c(0.5, 0.5),
               c(0.5, 0.5)) # balanced design

# hypothesized effects
#b1 <- 4
#b2 <- 4
b1 <- 0.5
b2 <- 0.5 # using b1 = b2.
#b3 <- -0.6
b3 <- 0
b0 <- 0 # same as alpha_0 in the above equation
b_main_list <- list('w1.1' = b1,
                    'w2.1' = b2) # average combination effect
b_2wy_list <- list('w1.1:w2.1' = b3) # two way interaction
sigma <- 2.5

```

```{r}
#### Outer loop to vary the experiment size
for (j in 1:length(possible.ns)) {
  N <- possible.ns[j]
  # Count number of levels in each factor
  L_list <- list()
  for(k in 1:length(p_list)){
    L_list[[paste0('L', k)]] <- length(p_list[[k]]) # naming the levels
  }
  number_marginal = (sum(unlist(L_list))-length(L_list)) # number of marginal effects
  paste0(number_marginal)

  # hold the p values and coefficients from both long and short models
  pvec <- cvec <- matrix(NA, sims, n)
  pvec_s <- cvec_s <- matrix(NA, sims, number_marginal)
    
  #### Inner loop to conduct experiments "sims" times over for each N ####
  for (i in 1:sims) {
    
    # apply the analysis function defined above
    fits <- lm_interacted_model(N,
                                p_list = p_list, # randomization probs
                                b0 = b0, # intercept
                                b_main_list = b_main_list, # main effects
                                b_2wy_list = b_2wy_list, # 2-way
                                b_3wy_list = NULL,# No 3-way interactions 
                                sigma = sigma)
    fit0 <- fits[[1]] # long model with interaction
    fit1 <- fits[[2]] # short model without interaction # TODO: not used not, check back see if needed
    
    ### To capture coefficients and pvalues, according to the hypothesis type
    for(h in 1:length(hypotheses)){
      if(hypotheses[h] == 'two.tailed'){
        pvec[i,h] <- summary(fit0)$coefficients[h + 1, 4] # pvalues for the h-th indicator (+1 due to intercept), 4th column: p-value for a two-sided test
        cvec[i,h] <- TRUE     # check if sign of coefficient is consistent with the hypothesis
      } else if (hypotheses[h] == 'greater'){
        pvec[i,h] <- pt(coef(summary(fit0))[h + 1, 3], fit0$df[h + 1], # 3rd column: t-stat
                        lower.tail = FALSE
        )
        cvec[i,h] <- summary(fit0)$coefficients[h + 1, 1]>0 # greater: >0 
      } else if (hypotheses[h] == 'lower'){
        pvec[i,h] <- pt(coef(summary(fit0))[h + 1, 3], fit0$df[h + 1],
                        lower.tail = TRUE) 
        cvec[i,h] <- summary(fit0)$coefficients[h + 1, 1]<0 # lower: <0
      }
    }
    # from short model without interactions
    for(s in 1:number_marginal){
      if(hypotheses[s] == 'two.tailed'){
        pvec_s[i,s] <- summary(fit1)$coefficients[s + 1, 4] 
        
        cvec_s[i,s] <- TRUE
      } else if (hypotheses[s] == 'greater'){
        pvec_s[i,s] <- pt(coef(summary(fit1))[s + 1, 3], fit1$df[s + 1],
                        lower.tail = FALSE
        )
        cvec_s[i,s] <- summary(fit1)$coefficients[s + 1, 1]>0
      } else if (hypotheses[s] == 'lower'){
        pvec_s[i,s] <- pt(coef(summary(fit1))[s + 1, 3], fit1$df[s + 1],
                        lower.tail = TRUE) 
        cvec_s[i,s] <- summary(fit1)$coefficients[s + 1, 1]<0
      }
    }
}


  
  # power for detecting the chosen interaction with index m
  power.interaction[j] <- mean(sapply(1:sims, function(x)
    cvec[x, m]*(pvec[x, m]<alpha) # not adjusted since only testing one hypothesis
    )) # get pvalues and coefficients of the relevant interaction term
  
  # power for detecting at least one interaction
  # power.atleastoneinteraction[j] <- mean(sapply(1:sims, function(x)
    #max(cvec[x, (sum(unlist(L_list))-length(L_list)+1):n]*(pvac[x, (sum(unlist(L_list))-length(L_list)+1):n]<alpha/n) )
    #) # get pvalues and coefficients of the interaction term
    
  # power for detecting at least one marginal effect
  power.onemarginal[j] <- mean(sapply(1:sims, function(x)
    max(cvec_s[x,]*(pvec_s[x,]<alpha/number_marginal))==1)) # Bonferroni or FDR
  
  # power for detecting all marginal effects
  power.allmarginals[j] <- mean(sapply(1:sims, function(x) 
    all(cvec_s[x,]*(pvec_s[x,]<(alpha/number_marginal))) )) # Bonferroni
  
  # note that power for detecting at least one is the same with Bonferroni or FDR, but not the power for detecting all effects
  power.all_FDR[j] <- mean(sapply(1:sims, function(x) 
    all(cvec_s[x,]*(pvec_s[x,]<alpha)) )) # FDR - cutoff for the max pvalue is alpha
}

```

```{r power_simulated_graph}

# save simulated power data
gg_df2 <- data.frame(
  N = possible.ns, 
  Interaction = power.interaction,
  `At least one` = power.onemarginal,
  `All with Bonferroni` = power.allmarginals,
  `All with FDR` = power.all_FDR
)

# start the plot
gg_df2 <- gg_df2 %>% melt(
  id.vars = "N", value.name = "Power", # the y-axis
  variable.name = "Type" # legend
)

# plotting power against sample size by type of power
ggplot(data = gg_df2, aes(x = N, y = Power, group = Type, col = Type)) + # power against size
  geom_point() +
  # vertical line indicating sample size where power first exceeds 0.8
  geom_segment(aes(
    x = possible.ns[min(which(power.interaction>0.8))],
    y = 0,
    xend = possible.ns[min(which(power.interaction>0.8))],
    yend = 0.8
  ),
  data = gg_df2, colour = "blue", lty = "dashed"
  ) +
  # horizontal line indicating sample size where power first exceeds 0.8
  geom_segment(aes(
    x = min(possible.ns),
    y = 0.8,
    xend = possible.ns[min(which(power.interaction>0.8))],
    yend = 0.8
  ),
  data = gg_df2, colour = "blue", lty = "dashed"
  ) +
  # vertical line indicating sample size where power first exceeds 0.8
  geom_segment(aes(
    x = possible.ns[min(which(power.allmarginals>0.8))],
    y = 0,
    xend = possible.ns[min(which(power.allmarginals>0.8))],
    yend = 0.8
  ),
  data = gg_df2, colour = "blue", lty = "dashed"
  ) +
  # horizontal line indicating sample size where power first exceeds 0.8
  geom_segment(aes(
    x = min(possible.ns),
    y = 0.8,
    xend = possible.ns[min(which(power.allmarginals>0.8))],
    yend = 0.8
  ),
  data = gg_df2, colour = "blue", lty = "dashed"
) +
  # vertical line indicating sample size where power first exceeds 0.8
  geom_segment(aes(
    x = possible.ns[min(which(power.all_FDR>0.8))],
    y = 0,
    xend = possible.ns[min(which(power.all_FDR>0.8))],
    yend = 0.8
  ),
  data = gg_df2, colour = "blue", lty = "dashed"
  ) +
  # horizontal line indicating sample size where power first exceeds 0.8
  geom_segment(aes(
    x = min(possible.ns),
    y = 0.8,
    xend = possible.ns[min(which(power.all_FDR>0.8))],
    yend = 0.8
  ),
  data = gg_df2, colour = "blue", lty = "dashed"
  ) +
  # vertical line indicating sample size where power first exceeds 0.8
  geom_segment(aes(
    x = possible.ns[min(which(power.onemarginal>0.8))],
    y = 0,
    xend = possible.ns[min(which(power.onemarginal>0.8))],
    yend = 0.8
  ),
  data = gg_df2, colour = "blue", lty = "dashed"
  ) +
  # horizontal line indicating sample size where power first exceeds 0.8
  geom_segment(aes(
    x = min(possible.ns),
    y = 0.8,
    xend = possible.ns[min(which(power.onemarginal>0.8))],
    yend = 0.8
  ),
  data = gg_df2, colour = "blue", lty = "dashed"
  ) +
  scale_y_continuous(breaks = seq(0.2, 1, .2)) # y axis scale
```


---

## Analysis Scripts

```{r analysis_loaddata}
library("tidyverse")
library("estimatr")
# Add your code for analysis
dta <- read_csv("data/hypothesis_test_df.csv")
names(dta) <- tolower(names(dta))
```

```{r process_data}
dta$no_visual = 1 - dta$visual
dta$interaction = dta$no_visual * dta$interactive

dta$prequiz_avg_123 = (dta$prequiz_q1_1 + dta$prequiz_q2_1 + dta$prequiz_q3_1)/3.0
dta$postquiz_avg_123 = (dta$postquiz_q1_1 + dta$postquiz_q2_1 + dta$postquiz_q3_1)/3.0
dta$prequiz_avg_456 = (dta$prequiz_q4_1 + dta$prequiz_q5_1 + dta$prequiz_q6_1)/3.0
dta$postquiz_avg_456 = (dta$postquiz_q4_1 + dta$postquiz_q5_1 + dta$postquiz_q6_1)/3.0

dta$pre_score = dta$prequiz_avg_123
dta$post_score = dta$postquiz_avg_123
```

Here, we test our main hypothesis. Is there significant difference between different interventions on the post-test score? We find that there are no significant results. 

We first see that the effect due to interaction between the 2 variables is not significant with Bonferroni correction.

```{r hyp_interaction}
lm <- lm_robust(post_score ~ pre_score + interaction, dta)
summary(lm)$coefficient

``` 

We get p-values for interactive and no_visual as > 0.05. So, they are not statistically significant.

```{r main_hyp}
lm <- lm_robust(post_score ~ pre_score + interactive + no_visual, dta)
summary(lm)$coefficient


```

Now, we run our secondary hypothesis as defined in the MEMO document (please look at README.md). Here, we use an updated version of the score to penalize making a participant more skeptical. We find that having interactive treatment hurts the final score in a statistically significant way.

```{r sec_hyp_process}
# get the average scores

dta$pre_score_sec = dta$prequiz_avg_123 - dta$prequiz_avg_456
dta$post_score_sec = dta$postquiz_avg_123 - dta$postquiz_avg_456

```

We first see that the effect due to interaction between the 2 variables is not significant with Bonferroni correction. p-value = 0.0276.

```{r sec_hyp_interaction}
lm <- lm_robust(post_score_sec ~ pre_score_sec + interaction, dta)
summary(lm)$coefficient

``` 

Now, we run the hypothesis test. We see that interactive has a p-value of 0.013 which is significant with Bonferroni correction and alpha=0.05.

```{r sec_hyp}
lm <- lm_robust(post_score_sec ~ pre_score_sec + interactive + no_visual, dta)
summary(lm)$coefficient

``` 
